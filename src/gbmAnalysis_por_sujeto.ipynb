{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWFvJz82R0qKb+KEY/ZSJh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["El objetivo de este código es implementar el algoritmo GBM, separando los datos por sujeto.\n"],"metadata":{"id":"r2FeK7ER0lvm"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/repo_tesis/entorno_tesis_Molina\"\n","!source bin/activate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zgm8tr-W0iGg","executionInfo":{"status":"ok","timestamp":1712497313559,"user_tz":180,"elapsed":215239,"user":{"displayName":"Manuel Molina","userId":"00131226921384183243"}},"outputId":"37632a10-25bc-4499-acc0-58aed320b9a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/repo_tesis/entorno_tesis_Molina\n"]}]},{"cell_type":"code","source":["# !pip install comet_ml\n","\n","# Importo las librerías\n","from lightgbm import LGBMClassifier\n","import numpy as np\n","from joblib import load\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n","import seaborn as sns\n","import time\n","from comet_ml import Experiment\n","import joblib\n","import matplotlib.pyplot as plt\n","\n","# Levanto los datos\n","features = load(\"/content/drive/My Drive/repo_tesis/data/FEATURES_W200_I50.joblib\")\n","label = load(\"/content/drive/My Drive/repo_tesis/data/label_W200_I50.joblib\")"],"metadata":{"id":"vXY4UCY_1yNX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Construyo cada conjunto de datos haciendo la división por sujeto.\n","\n","\n","*   Dos sujetos para test.\n","*   Dos sujetos para validación.\n","*   El resto para entrenamiento.\n","\n","Esto lo dejé así por defecto pero puede modificarse fácilmente."],"metadata":{"id":"VVOz8EW17wgX"}},{"cell_type":"code","source":["# Calculo la cantidad de sujetos\n","label = np.array(label)\n","cantSujetos = np.max(label[:, 2])\n","\n","# Hago un sorteo a ver que sujeto va para cada conjunto\n","sorteo = np.random.permutation(cantSujetos) + 1\n","\n","# El primer sujeto del sorteo va a test, el segundo a val y el resto a train\n","indices_test = list(np.where(label[:, 2]==sorteo[0])[0])\n","indices_val = list(np.where(label[:, 2]==sorteo[2])[0])\n","\n","indices_test.extend(list(np.where(label[:, 2]==sorteo[1])[0]))\n","indices_val.extend(list(np.where(label[:, 2]==sorteo[3])[0]))\n","\n","indices_train = []\n","for j in sorteo[4:]:\n","    indices_train.extend(np.where(label[:, 2]==j)[0])\n","\n","# lo paso a numpy array para poder definir de forma mas comoda los conjuntos de train test y val\n","features = np.array(features)\n","\n","X_train = features[indices_train, :]\n","y_train = label[indices_train, 1]\n","X_val = features[indices_val, :]\n","y_val = label[indices_val, 1]\n","X_test =  features[indices_test, :]\n","y_test = label[indices_test, 1]"],"metadata":{"id":"kTNOyyI17z7z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Voy a usar la implementación que me dio ChatGPT, ya que en la tesis de Renato no se habla de cómo elegir los parámetros"],"metadata":{"id":"5ouU9XFH5m7e"}},{"cell_type":"code","source":["start_time = time.time()    # comienzo a medir el tiempo\n","\n","# Crear una instancia de LGBMClassifier\n","clf = LGBMClassifier()\n","\n","# Entrenar el clasificador\n","clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='logloss')\n","\n","# Finalizo la medida del tiempo y calculo el tiempo de entrenamiento\n","end_time = time.time()\n","training_time = end_time - start_time\n","\n","# # Realizar predicciones en el conjunto de validación\n","# y_pred = clf.predict(X_val)\n","\n","# # Calcular la precisión\n","# accuracy = accuracy_score(y_val, y_pred)\n","# print(f'Accuracy: {accuracy}')\n","\n","# Obtener las iteraciones del mejor modelo\n","best_iteration = clf.best_iteration_\n","\n","# Imprimir la advertencia si existe\n","if hasattr(clf, 'best_iteration_') and clf.best_iteration_ is None:\n","    print(\"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UACEGaVYADkQ","executionInfo":{"status":"ok","timestamp":1711645283342,"user_tz":180,"elapsed":125787,"user":{"displayName":"Manuel Molina","userId":"00131226921384183243"}},"outputId":"e8fb0d59-1994-4756-f5ea-f6a9349b756d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216863 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 50308\n","[LightGBM] [Info] Number of data points in the train set: 37655, number of used features: 240\n","[LightGBM] [Info] Start training from score -2.565481\n","[LightGBM] [Info] Start training from score -2.592793\n","[LightGBM] [Info] Start training from score -2.601708\n","[LightGBM] [Info] Start training from score -2.591020\n","[LightGBM] [Info] Start training from score -2.573805\n","[LightGBM] [Info] Start training from score -2.543614\n","[LightGBM] [Info] Start training from score -2.547339\n","[LightGBM] [Info] Start training from score -2.549036\n","[LightGBM] [Info] Start training from score -2.549036\n","[LightGBM] [Info] Start training from score -2.601708\n","[LightGBM] [Info] Start training from score -2.376846\n","[LightGBM] [Info] Start training from score -2.547339\n","[LightGBM] [Info] Start training from score -2.740986\n","Accuracy: 0.326323695080736\n"]}]},{"cell_type":"markdown","source":["Voy a guardar el clasificador, y evaluar distintas métricas: accuracy, precision y recall. Voy a hacer una matriz de confusión.\n","Por otra parte, voy a guardar la partición de los datos para hacer reproducible el experimento."],"metadata":{"id":"PG01odhb9_vZ"}},{"cell_type":"code","source":["# Guardar el modelo entrenado en un archivo\n","joblib.dump(bst, 'baseline_gbm_sep_sub_r1.pkl')\n","\n","# Predecir en el conjunto de test\n","y_pred = bst.predict(X_test)\n","\n","# Calcular métricas de desempeño\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Mostrar las métricas\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","\n","# Visualizar la matriz de confusión\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Guardar la imagen de la matriz de confusión\n","plt.savefig(\"confusion_matrix.png\")"],"metadata":{"id":"372jmwPC-Ae2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Voy a guardar las métricas calculadas en un experimento en Comet"],"metadata":{"id":"WuPIwaqLVn6f"}},{"cell_type":"code","source":["# Conectar con Comet\n","API_KEY = 'ehXeElNypcj7Knar5zTmyjwSO' # Se puede encontrar en Settings(Arriba a la derecha en Comet)\n","\n","# Crear un experimento con mi API KEY\n","exp = Experiment(api_key=API_KEY,\n","                 project_name='tesis-experimentos', # Nombre del proyecto donde se registran los experimentos\n","                 auto_param_logging=False)\n","exp.set_name('baseline_gbm_sep_sub_r1') # Nombre de este experimento\n","exp.add_tags(['baseline', 'gbm', 'sep_sub']) # Tags\n","\n","exp.log_metric(\"accuracy\", accuracy)\n","exp.log_metric(\"precision\", precision)\n","exp.log_metric(\"recall\", recall)\n","exp.log_metric(\"training_time\", training_time)\n","exp.log_confusion_matrix(y_test, y_pred)\n","exp.log_parameter(\"partition_array\", sorteo)   # Guarda el arreglo en el experimento\n","exp.log_text(\"Primeros dos sujetos --> test, tercero y cuarto --> validación, resto --> train. \\n Corresponde a la primera ronda que entreno con estos parámetros. \")   # Comentario del experimento"],"metadata":{"id":"-fEFgzjFVuTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Subir el modelo\n","exp.log_model(name=\"baseline_gbm_sep_sub_r1\", file_or_folder=\"baseline_gbm_sep_sub_r1.pkl\")\n","exp.end()"],"metadata":{"id":"aMudfUD3V6TS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Junto todo en un bloque de código"],"metadata":{"id":"KuoXHICo0EN3"}},{"cell_type":"code","source":["%cd \"/content/drive/My Drive/repo_tesis/archivos_generados_codigos\"\n","\n","for k in range(1,2):\n","  label = np.array(label)\n","  cantSujetos = np.max(label[:, 2])\n","  sujeto_test = k\n","  sorteo = np.random.permutation(cantSujetos) + 1\n","  sorteo_sin_test = np.delete(sorteo, np.where(sorteo == sujeto_test))\n","  indices_test = list(np.where(label[:, 2]==sujeto_test)[0])\n","  indices_val = list(np.where(label[:, 2]==sorteo_sin_test[0])[0])\n","  indices_val.extend(list(np.where(label[:, 2]==sorteo_sin_test[1])[0]))\n","\n","  indices_train = []\n","  for j in sorteo_sin_test[2:]:\n","      indices_train.extend(np.where(label[:, 2]==j)[0])\n","  features = np.array(features)\n","\n","  X_train = features[indices_train, :]\n","  y_train = label[indices_train, 1]\n","  X_val = features[indices_val, :]\n","  y_val = label[indices_val, 1]\n","  X_test =  features[indices_test, :]\n","  y_test = label[indices_test, 1]\n","\n","  start_time = time.time()\n","\n","  # implemento gbm\n","  clf = LGBMClassifier()\n","  clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='logloss')\n","\n","  end_time = time.time()\n","  training_time = end_time - start_time\n","  # Obtener las iteraciones del mejor modelo\n","  bst = clf.best_iteration_\n","\n","  nombre = 'baseline_gbm_sep_sub' + str(k) + '_testing'\n","\n","  joblib.dump(clf, nombre + '.pkl')\n","\n","  y_pred = clf.predict(X_test)\n","\n","  accuracy = accuracy_score(y_test, y_pred)\n","  precision = precision_score(y_test, y_pred, average='weighted')\n","  recall = recall_score(y_test, y_pred, average='weighted')\n","  conf_matrix = confusion_matrix(y_test, y_pred)\n","  plt.savefig(\"confusion_matrix.png\")\n","\n","  API_KEY = 'ehXeElNypcj7Knar5zTmyjwSO'\n","\n","  exp = Experiment(api_key=API_KEY,\n","                  project_name='tesis-experimentos', # Nombre del proyecto donde se registran los experimentos\n","                  auto_param_logging=False)\n","  exp.set_name(nombre) # Nombre de este experimento\n","  exp.add_tags(['baseline', 'gbm', 'sep_sub', 'choose_test']) # Tags\n","\n","  exp.log_metric(\"accuracy\", accuracy)\n","  exp.log_metric(\"precision\", precision)\n","  exp.log_metric(\"recall\", recall)\n","  exp.log_metric(\"training_time\", training_time)\n","  exp.log_confusion_matrix(y_test, y_pred)\n","  exp.log_parameter(\"partition_array\", sorteo)   # Guarda el arreglo en el experimento\n","  exp.log_text(\"Se fija el sujeto de test y se sortea el resto. Los primeros dos sujetos del sorteo son los de validación.\")   # Comentario del experimento\n","  exp.log_model(name=nombre, file_or_folder=nombre + '.pkl')\n","  exp.end()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939},"id":"4lU6r-TU0G9L","executionInfo":{"status":"ok","timestamp":1712501041150,"user_tz":180,"elapsed":121164,"user":{"displayName":"Manuel Molina","userId":"00131226921384183243"}},"outputId":"655633be-5a26-472a-d153-7d4d8ce8a77f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/repo_tesis/archivos_generados_codigos\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.541994 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 50345\n","[LightGBM] [Info] Number of data points in the train set: 45226, number of used features: 240\n","[LightGBM] [Info] Start training from score -2.565215\n","[LightGBM] [Info] Start training from score -2.600029\n","[LightGBM] [Info] Start training from score -2.605103\n","[LightGBM] [Info] Start training from score -2.578238\n","[LightGBM] [Info] Start training from score -2.572718\n","[LightGBM] [Info] Start training from score -2.544725\n","[LightGBM] [Info] Start training from score -2.544161\n","[LightGBM] [Info] Start training from score -2.547263\n","[LightGBM] [Info] Start training from score -2.552927\n","[LightGBM] [Info] Start training from score -2.595573\n","[LightGBM] [Info] Start training from score -2.382079\n","[LightGBM] [Info] Start training from score -2.553779\n","[LightGBM] [Info] Start training from score -2.737011\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, lightgbm.\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/manuelmolinach99/tesis-experimentos/bd0cddec9e424fa4bd23561cf03d600f\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/manuelmolinach99/tesis-experimentos/bd0cddec9e424fa4bd23561cf03d600f\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     accuracy      : 0.25368837711406983\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     precision     : 0.26482242684700047\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     recall        : 0.25368837711406983\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     training_time : 113.34423160552979\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : baseline_gbm_sep_sub1_testing\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     partition_array : [ 4  7  2  3  5  1 10  9  8  6]\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (678.42 KB)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element            : 1 (4.34 MB)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, lightgbm.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]}]}